1. Rate limiting : A way to control the number of requests a client (like a user, app or system) can make to a server within a specific period.
2. Load balancing : A way to distribute incoming requests or traffic across multiple servers to ensure no single server gets overloaded.
3. Caching : A way to store frequently accesses data temporarily so that it can be retrieved quickly without repeatedly fetching it from original source.
4. CDN : A network of servers distributed across different locations that work together to deliver content to users more quickly.
5. Microservices : An architectural style where an application is divided into smaller, independent services, each responsible for a specific piece of functionality.
6. API Gateway : A server that acts as an entry point for all client requests to your system. It routes those request to the appropriate microservice, handles load balancing and other tasks.
7. Webhooks : A way for one application to send real-time updates or notifications to another application when a specific event happens.
8. Sharding : Method of splitting large database into smaller, more manageble pieces called shards.
9. Proxy : Server that acts as an intermediary between client (like browser) and another server (like a website).
10. Message Queues : System used to send, store and retrieve messages between different parts of an application (or between applications) in a reliable and organized way.
