FUNDAMENTALS:
Resources - Azure AI Speech

1. Speech to text:Speech recognition
2. Text to speech:Speech synthesis
3. Speech Translation
4. Speaker Recognition:Recognize individual speakers based on their voice.
5. Intent Recognition:Conversational language understanding to determine the semantic meaning of spoken input.

- Speech to text API: batch transcription
- Speech to text Short Audio API: short speech upto 60 sec
- Text to speech API
- Batch synthesis API
- Speech Synthesis Markup Language (SSML)
- SpeechRecognizer Object - SpeechConfig & AudioConfig - Speech API

Steps:

1. Speech recognition - the ability to detect and interpret spoken input
2. Acoustic model - Audio signal to phonemes + Language model - phonemes mapped to words.
3. Words converted to text
4. Speech synthesis - the ability to generate spoken output

Azure AI Speech:

1. Speech to text API - Microsoft-owned and deployed to Microsoft Azure: Universal Language Model
   Real-time transcription, Batch transcription
2. Text to speech API - Speech synthesis voices

- Call the speech API
- Process the response

Analyse text and process speech

- Key phrase extraction
- Entity recognition
- Sentiment analysis
- Language detection

---

TRANSLATION:
Resource:
Single service: Azure AI Translator
Multi service: Text Analytics API

1. Language detection - Detect function
2. Translation - Translate function - from parameter and multiple to parameters
3. Transliteration - Transliterate function - fromScript parameter and toScript parameter

Translation options:

1. Word alignment
2. Sentence length
3. Profanity filtering

SpeechTranslationConfig + AudioConfig => TranslationRecognizer => RecognizeOnceAsync() => SpeechRecognitionResult object

- TranslationRecognizer

1. Event-based synthesis - 1:1 translations
2. Manual synthesis - 1:multiple translations

---

TEXT TO SPEECH:

- Can specify speech synthesis voices

SpeechSynthesizer object
SpeechConfig: Location & key
AudioConfig: Output device such as speaker or file in which output must be written
SpeechConfig + AudioConfig => Speech synthesizer => SpeakTextAsync() => SpeechSynthesisResult object

---

SPEECH TO TEXT:

1. Real-time transcription
2. Batch transcription

SpeechRecognizer object
SpeechConfig: Location & key
AudioConfig: Input such as microphone or file which must be input
SpeechConfig + AudioConfig => Speech Recognizer => RecognizeOnceAsync() => SpeechRecognitionResult object

---
